<!DOCTYPE html>
<html lang="zh-hant">
    <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#"><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="UTF-8" />

    <meta name="generator" content="Hugo 0.131.0"><meta name="theme-color" content="#fff" />
    <meta name="color-scheme" content="light dark">

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <meta name="format-detection" content="telephone=no, date=no, address=no, email=no" />
    
    <meta http-equiv="Cache-Control" content="no-transform" />
    
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <title>使用Barracuda在Unity3D中实现图像识别 | illumination</title>

    <link rel="stylesheet" href="/css/meme.min.css" />

    
    
        
            <script src="/js/meme.min.js"></script>

        
    

    

    <meta name="author" content="Mingxian" /><meta name="description" content="介绍使用 Barracuda 在 Unity3D 中运行机器学习模型。这允许您在 Unity 视频游戏引擎中以 onnx 的格式运行大多数的机……" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#fff" />
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="illumination" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="application-name" content="illumination" />
    <meta name="msapplication-starturl" content="../../" />
    <meta name="msapplication-TileColor" content="#fff" />
    <meta name="msapplication-TileImage" content="../../icons/mstile-150x150.png" />
    <link rel="manifest" href="/manifest.json" />

    
    

    
        <link rel="canonical" href="http://localhost:1313/tech/image-recognition-in-unity3d-using-barracuda/" />
    

<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "datePublished": "2022-10-29T18:10:00+08:00",
        "dateModified": "2024-08-11T18:07:15+08:00",
        "url": "http://localhost:1313/tech/image-recognition-in-unity3d-using-barracuda/",
        "headline": "使用Barracuda在Unity3D中实现图像识别",
        "description": "介绍使用 Barracuda 在 Unity3D 中运行机器学习模型。这允许您在 Unity 视频游戏引擎中以 onnx 的格式运行大多数的机……",
        "inLanguage" : "zh-hant",
        "articleSection": "tech",
        "wordCount":  4292 ,
        "image": "http://localhost:1313/icons/apple-touch-icon.png",
        "author": {
            "@type": "Person",
            "description": "當你下定決心 結局便成了副產物",
            "email": "yangmingxian2015@gmail.com",
            "image": "http://localhost:1313/icons/apple-touch-icon.png",
            "url": "https://yangmingxian.com/",
            "name": "Mingxian"
        },
        "license": "在保留本文作者及本文連結的前提下，非商業用途經作者同意后轉載分享。",
        "publisher": {
            "@type": "Organization",
            "name": "illumination",
            "logo": {
                "@type": "ImageObject",
                "url": "http://localhost:1313/icons/apple-touch-icon.png"
            },
            "url": "http://localhost:1313/"
        },
        "mainEntityOfPage": {
            "@type": "WebSite",
            "@id": "http://localhost:1313/"
        }
    }
</script>

    

<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@CyberStreamer" />
<meta name="twitter:creator" content="@CyberStreamer" />

    



<meta property="og:title" content="使用Barracuda在Unity3D中实现图像识别" />
<meta property="og:description" content="介绍使用 Barracuda 在 Unity3D 中运行机器学习模型。这允许您在 Unity 视频游戏引擎中以 onnx 的格式运行大多数的机……" />
<meta property="og:url" content="http://localhost:1313/tech/image-recognition-in-unity3d-using-barracuda/" />
<meta property="og:site_name" content="illumination" />
<meta property="og:locale" content="zh-hant" /><meta property="og:image" content="http://localhost:1313/icons/apple-touch-icon.png" />
    <meta property="og:type" content="article" />
    <meta property="article:published_time" content="2022-10-29T18:10:00&#43;08:00" />
    <meta property="article:modified_time" content="2024-08-11T18:07:15&#43;08:00" />
    
    <meta property="article:section" content="tech" />



    
    

    

<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@700&amp;text=reuixiy&amp;display=swap" media="print" onload="this.media='all'" />
<noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@700&amp;text=reuixiy&amp;display=swap" /></noscript>

</head>

    <body>
        <div class="container">
            
    <header class="header">
        
            <div class="header-wrapper">
                <div class="header-inner single">
                    
    <div class="site-brand">
        
            <a href="/" class="brand">illumination</a>
        
    </div>

                    <nav class="nav">
    <ul class="menu" id="menu">
        

        
            
                <li class="menu-item"><a href="/life/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon life"><path d="M301.1 212c4.4 4.4 4.4 11.9 0 16.3l-9.7 9.7c-4.4 4.7-11.9 4.7-16.6 0l-10.5-10.5c-4.4-4.7-4.4-11.9 0-16.6l9.7-9.7c4.4-4.4 11.9-4.4 16.6 0l10.5 10.8zm-30.2-19.7c3-3 3-7.8 0-10.5-2.8-3-7.5-3-10.5 0-2.8 2.8-2.8 7.5 0 10.5 3.1 2.8 7.8 2.8 10.5 0zm-26 5.3c-3 2.8-3 7.5 0 10.2 2.8 3 7.5 3 10.5 0 2.8-2.8 2.8-7.5 0-10.2-3-3-7.7-3-10.5 0zm72.5-13.3c-19.9-14.4-33.8-43.2-11.9-68.1 21.6-24.9 40.7-17.2 59.8.8 11.9 11.3 29.3 24.9 17.2 48.2-12.5 23.5-45.1 33.2-65.1 19.1zm47.7-44.5c-8.9-10-23.3 6.9-15.5 16.1 7.4 9 32.1 2.4 15.5-16.1zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-66.2 42.6c2.5-16.1-20.2-16.6-25.2-25.7-13.6-24.1-27.7-36.8-54.5-30.4 11.6-8 23.5-6.1 23.5-6.1.3-6.4 0-13-9.4-24.9 3.9-12.5.3-22.4.3-22.4 15.5-8.6 26.8-24.4 29.1-43.2 3.6-31-18.8-59.2-49.8-62.8-22.1-2.5-43.7 7.7-54.3 25.7-23.2 40.1 1.4 70.9 22.4 81.4-14.4-1.4-34.3-11.9-40.1-34.3-6.6-25.7 2.8-49.8 8.9-61.4 0 0-4.4-5.8-8-8.9 0 0-13.8 0-24.6 5.3 11.9-15.2 25.2-14.4 25.2-14.4 0-6.4-.6-14.9-3.6-21.6-5.4-11-23.8-12.9-31.7 2.8.1-.2.3-.4.4-.5-5 11.9-1.1 55.9 16.9 87.2-2.5 1.4-9.1 6.1-13 10-21.6 9.7-56.2 60.3-56.2 60.3-28.2 10.8-77.2 50.9-70.6 79.7.3 3 1.4 5.5 3 7.5-2.8 2.2-5.5 5-8.3 8.3-11.9 13.8-5.3 35.2 17.7 24.4 15.8-7.2 29.6-20.2 36.3-30.4 0 0-5.5-5-16.3-4.4 27.7-6.6 34.3-9.4 46.2-9.1 8 3.9 8-34.3 8-34.3 0-14.7-2.2-31-11.1-41.5 12.5 12.2 29.1 32.7 28 60.6-.8 18.3-15.2 23-15.2 23-9.1 16.6-43.2 65.9-30.4 106 0 0-9.7-14.9-10.2-22.1-17.4 19.4-46.5 52.3-24.6 64.5 26.6 14.7 108.8-88.6 126.2-142.3 34.6-20.8 55.4-47.3 63.9-65 22 43.5 95.3 94.5 101.1 59z"/></svg><span class="menu-item-name">生活</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/tech/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tech"><path d="M512 256c0 141.2-114.7 256-256 256C114.8 512 0 397.3 0 256S114.7 0 256 0s256 114.7 256 256zm-32 0c0-123.2-100.3-224-224-224C132.5 32 32 132.5 32 256s100.5 224 224 224 224-100.5 224-224zM160.9 124.6l86.9 37.1-37.1 86.9-86.9-37.1 37.1-86.9zm110 169.1l46.6 94h-14.6l-50-100-48.9 100h-14l51.1-106.9-22.3-9.4 6-14 68.6 29.1-6 14.3-16.5-7.1zm-11.8-116.3l68.6 29.4-29.4 68.3L230 246l29.1-68.6zm80.3 42.9l54.6 23.1-23.4 54.3-54.3-23.1 23.1-54.3z"/></svg><span class="menu-item-name">技术</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/about/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon about"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6 0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7 0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4 0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9 14.3 0 28-2.7 40.9-6.9 2.3-.7 4.7-1.1 7.1-1.1 42.9 0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z"/></svg><span class="menu-item-name">自述</span></a>
                </li>
            
        
            
                
                    
                    
                        <li class="menu-item">
                            <a id="theme-switcher" href="#"><span class="icon theme-icon-light">🌞</span><span class="icon theme-icon-dark">🌙</span></a>
                        </li>
                    
                
            
        
            
                
            
        
    </ul>
</nav>

                    
                </div>
            </div>
            
    <input type="checkbox" id="nav-toggle" aria-hidden="true" />
    <label for="nav-toggle" class="nav-toggle"></label>
    <label for="nav-toggle" class="nav-curtain"></label>


        
    </header>




            
            
    <main class="main single" id="main">
    <div class="main-inner">

        

        <article class="content post h-entry" data-align="justify" data-type="tech" data-toc-num="true">

            <h1 class="post-title p-name">使用Barracuda在Unity3D中实现图像识别</h1>

            

            
                
            

            

            <div class="post-body e-content">
                <blockquote>
<p>介绍使用 Barracuda 在 Unity3D 中运行机器学习模型。这允许您在 Unity 视频游戏引擎中以 onnx 的格式运行大多数的机器学习模型，以便在 Android 或 iOS 上提供跨平台支持。这个教程是我在学习过程中的学习分享，适合新手作为一个学习参考。</p>
</blockquote>
<p><img alt="识别结果截图" src="/images/2022/image_recognition_result.png"></p>
<hr>
<blockquote>
<p>(已过时，待更新) 在这个Unity 教程中，我将介绍使用 Barracuda 在 Unity3D 中运行机器学习模型。这允许您在 Unity 视频游戏引擎中以 onnx 的格式运行大多数的机器学习模型，以便在 Android 或 iOS 上提供跨平台支持。这个教程是我在学习过程中的学习分享，不会涉及到机器学习的内容以及集成Unity3D过程中很深的内容，很适合新手作为一个学习参考。</p>
</blockquote>
<h2 id="前言"><a href="#前言" class="anchor-link">#</a>前言</h2>
<p>最近我暂时搁置了我正在独立开发的游戏，因为我想让自己的独立作品包含一些新鲜玩意。我一直尝试在Unity3D中集成一个节奏识别的深度学习网络，我参考并且尝试了一些解决方案，但是都不能达到一个类似于Conda的环境支持。当然，开发环境中运行深度学习已不是什么新鲜事了，但是在runtime中运行任意一个深度学习网络，在玩家游玩的过程中使用各式各样的机器学习模型才是我所追求的。</p>
<h2 id="解决方案对比"><a href="#解决方案对比" class="anchor-link">#</a>解决方案对比</h2>
<p>我尝试了一些Unity3D官方提供的和其他我所找到的解决防范，下面简单列举一下它们的优劣：</p>
<ul>
<li>Python for unity：
<ul>
<li>使用简单，官方提供了完整的安装包，可以直接安装</li>
<li>支持Python的第三方库，引用或者在项目路径添加 site-packages 即可</li>
<li>不支持Runtime和成品打包，代码属于一个UnityEditor的扩展</li>
<li>无法更改各种Python包的版本，会出现各种问题</li>
</ul>
</li>
<li>Pythonnet：
<ul>
<li>它属于Python for unity的外源，Python for unity就是使用了这个库开发的，可以在Unity3D的Github上找到一摸一样的fork源码，属于原生的Python for unity了</li>
<li>它的优劣和 Python for unity 类似</li>
</ul>
</li>
<li>IronPython：
<ul>
<li>IronPython 是Python在.NET平台上的实现，支持Runtime集成</li>
<li>IronPython 其实也需要引入程序集和DLL，需要熟悉IronPython的内部实现</li>
<li>对于初级开发者而言，它比较适合小体量的Python脚本</li>
<li>不太适合深度学习的框架</li>
</ul>
</li>
<li>ML-Agent：
<ul>
<li>Unity3D官方的机器学习解决方案，安装简单，有大量的教程的文档、</li>
<li>支持和Anaconda协同环境（仅开发环境，不支持Runtime）</li>
<li>脱离了python的机器学习框架，Unity为了使它对非深度学习开发者更易用，做了自己的封装，使用了自己一套逻辑，以前使用的应该是TensorflowSharp做接口，用C#写逻辑。</li>
<li>虽然名字是ML-Agent，但是它并不能支持大部分机器学习的内容，更像是一些特定的强化学习模型，没有很强的定制化区间，而且除了Unity自己，其他开发者很少用这套东西做开发</li>
<li>不适合Python深度学习模型的集成，虽然你可以用Conda环境，但是想要把Conda环境中你训练好的模型直接做集成是不支持的。</li>
</ul>
</li>
<li>Barracuda：
<ul>
<li>Barracuda 是最贴近大多数机器学习集成的一套东西。使用简单，官方提供了完整的安装包，可以直接安装</li>
<li>支持比较多的模型：全卷积神经网络，全稠密网络，Tiny YOLO等，这里还支持所有的ML-Agent网络（Unity还是要支持自己的工具的）</li>
<li>适用于很多onnx网络</li>
<li>支持Runtime集成，用C#和模型做了输入和输出的接口</li>
<li>缺点就是它支持的网络取决于onnx模型，全卷积神经网络，全稠密网络等，能做的事情比较集中，图像识别，图像风格转换，表情识别等最经典的模型更适用一些，不支持其他新兴网络，比如stable disffusion等扩散模型和其他模型。</li>
</ul>
</li>
<li>自行封装DLL：
<ul>
<li>这部分看个乐就好了，独立开发者用的小型DLL还行，针对某一个网络做自己的DLL还是比较容易实现的，需要对DLL部分的知识很清楚...</li>
<li>如果你想集成类型多一些的神经网络，不要想了，Unity做了好几年的Barracuda，ML-Agent都没能解决，独立开发者还是不要尝试了。</li>
</ul>
</li>
</ul>
<p><em>//TODO : 如果有需要的话，我可以单独把每一个解决方案都写一下大致的集成教程，那可能涉及到很多零散的内容。</em></p>
<hr>
<h2 id="准备深度学习模型"><a href="#准备深度学习模型" class="anchor-link">#</a>准备深度学习模型</h2>
<p>我不准备在这里讲很多机器学习的内容。这里你需要将深度学习模型转换为onnx的格式，这部分可以看pytorch或者onnx的教程。</p>
<p><a href="https://github.com/yangmingxian/Unity-Image-Classification/blob/a6e874b5684537f54cea46187b6ff2f5bca174fe/Assets/Models/ImageClass.onnx" target="_blank" rel="noopener"><strong>模型的下载链接</strong></a><br>
<a href="https://github.com/yangmingxian/Unity-Image-Classification/blob/a6e874b5684537f54cea46187b6ff2f5bca174fe/Assets/Models/labels_map.txt" target="_blank" rel="noopener"><strong>标签的下载链接</strong></a></p>
<p>内容包含：ImageClass.onnx (深度学习模型)  labels_map.txt (识别标签)</p>
<p>我使用的是一个很简单的onnx模型，它是一个参数比较少的CNN模型，因为移动端的计算性能远低于PC或者集群服务器。该模型的而且在少量计算资源的情况下可以维持在30ms内识别结果。</p>
<p>这个模型训练使用到的数据集是ImageNet数据集，包含了1000个物体的标签，我通过电脑跑这个模型，并且使用了一些经过裁剪的图片时，准确率大概在80%左右。值得注意的是，因为手机像素以及其他因素，摄像头得到的图像识别率会降低一些，识别准确率和手机摄像机拍摄的照片质量有很强的联系。</p>
<p>我们需要用到的就是这个模型的输入和输出。</p>
<ul>
<li>输入：float32[1,224,224,3] (batch_size为1的224*224的RGB图像)</li>
<li>输出：float32[1,1000] 这是将索引映射到标签的分数，分数越大，对应标签的可能性越大</li>
</ul>
<h2 id="unity的场景设置"><a href="#unity的场景设置" class="anchor-link">#</a>Unity的场景设置</h2>
<p>Unity场景的设置很简单，我们只需要一个Canvas：其中有一个RawImage用于显示手机摄像机返回的图像，还有一个Button来交互，button上的文字就是识别的结果。除此之外，我还设置了一个空物体来存放推理和识别的脚本。</p>
<p><img alt="场景" src="/images/2022/unity_scene.png"></p>
<h2 id="关键脚本与流程"><a href="#关键脚本与流程" class="anchor-link">#</a>关键脚本与流程</h2>
<h3 id="手机摄像头的显示"><a href="#手机摄像头的显示" class="anchor-link">#</a>手机摄像头的显示</h3>
<p>首先是声明一个RawImage用来存放和显示摄像头的图像，这里我们额外设置了一个AspectRatioFitter组件用来设置将RawImage的比例设置成与手机屏幕比例一致。</p>
<p>然后我们通过使用WebCamTexture来读取摄像机的画面。(这里需要额外注意，可以通过设置RawImage的Z轴旋转为-90，否则手机屏幕会是翻转的。)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl"> <span class="k">void</span> <span class="n">Start</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">rawImage</span> <span class="p">=</span> <span class="n">GetComponent</span><span class="p">&lt;</span><span class="n">RawImage</span><span class="p">&gt;();</span>
</span></span><span class="line"><span class="cl">        <span class="n">fitter</span> <span class="p">=</span> <span class="n">GetComponent</span><span class="p">&lt;</span><span class="n">AspectRatioFitter</span><span class="p">&gt;();</span>
</span></span><span class="line"><span class="cl">        <span class="n">InitWebCam</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">webcamTexture</span><span class="p">.</span><span class="n">width</span> <span class="p">&gt;</span> <span class="m">100</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">fitter</span><span class="p">.</span><span class="n">aspectRatio</span> <span class="p">=</span> <span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">webcamTexture</span><span class="p">.</span><span class="n">width</span> <span class="p">/</span> <span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">webcamTexture</span><span class="p">.</span><span class="n">height</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">void</span> <span class="n">InitWebCam</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">string</span> <span class="n">camName</span> <span class="p">=</span> <span class="n">WebCamTexture</span><span class="p">.</span><span class="n">devices</span><span class="p">[</span><span class="m">0</span><span class="p">].</span><span class="n">name</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">webcamTexture</span> <span class="p">=</span> <span class="k">new</span> <span class="n">WebCamTexture</span><span class="p">(</span><span class="n">camName</span><span class="p">,</span> <span class="n">Screen</span><span class="p">.</span><span class="n">width</span><span class="p">,</span> <span class="n">Screen</span><span class="p">.</span><span class="n">height</span><span class="p">,</span> <span class="m">30</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">rawImage</span><span class="p">.</span><span class="n">texture</span> <span class="p">=</span> <span class="n">webcamTexture</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">webcamTexture</span><span class="p">.</span><span class="n">Play</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span></code></pre></div><h3 id="图像数据的预处理"><a href="#图像数据的预处理" class="anchor-link">#</a>图像数据的预处理</h3>
<p>得到原始的摄像机的图像之后，第一步要做的就是裁剪和重采样。因为我们的模型需要的输入是float32[1,224,224,3]</p>
<ul>
<li>首先第一个参数代表batch_size是1，我们每次读取一张图片就好</li>
<li>第2,3个参数224,224代表的是图像的大小</li>
<li>第四个参数3代表的是RGB通道</li>
</ul>
<p>所以我们需要把图像裁剪成正方形的，并且还需要对图像进行DownSample, 因为我们的输入需要的像素是224*224的，所以尽量保证数据源的像素高的同时，还需要把图片尽量不损失内容的情况下DownSample成我们需要的形状。</p>
<p>首先我们新建一个renderTexture用来存放结果，这里我们使用的格式是ARGB32. 然后通过Graphics.Blit函数，使用shader的方式来进行图像的裁剪和定位以及次采样. 然后我们通过AsyncGPUReadback来把GPU处理的renderTexture数据传到CPU用来计算。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl"><span class="kd">public</span> <span class="k">void</span> <span class="n">ScaleAndCropImage</span><span class="p">(</span><span class="n">WebCamTexture</span> <span class="n">webCamTexture</span><span class="p">,</span> <span class="kt">int</span> <span class="n">desiredSize</span><span class="p">,</span> <span class="n">UnityAction</span><span class="p">&lt;</span><span class="kt">byte</span><span class="p">[]&gt;</span> <span class="n">callback</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">this</span><span class="p">.</span><span class="n">callback</span> <span class="p">=</span> <span class="n">callback</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">renderTexture</span> <span class="p">==</span> <span class="kc">null</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">renderTexture</span> <span class="p">=</span> <span class="k">new</span> <span class="n">RenderTexture</span><span class="p">(</span><span class="n">desiredSize</span><span class="p">,</span> <span class="n">desiredSize</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="n">RenderTextureFormat</span><span class="p">.</span><span class="n">ARGB32</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">scale</span><span class="p">.</span><span class="n">x</span> <span class="p">=</span> <span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">webCamTexture</span><span class="p">.</span><span class="n">height</span> <span class="p">/</span> <span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">webCamTexture</span><span class="p">.</span><span class="n">width</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">offset</span><span class="p">.</span><span class="n">x</span> <span class="p">=</span> <span class="p">(</span><span class="m">1</span> <span class="p">-</span> <span class="n">scale</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="p">/</span> <span class="m">2f</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">Graphics</span><span class="p">.</span><span class="n">Blit</span><span class="p">(</span><span class="n">webCamTexture</span><span class="p">,</span> <span class="n">renderTexture</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">offset</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">AsyncGPUReadback</span><span class="p">.</span><span class="n">Request</span><span class="p">(</span><span class="n">renderTexture</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="n">TextureFormat</span><span class="p">.</span><span class="n">RGB24</span><span class="p">,</span> <span class="n">OnCompleteReadback</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span></code></pre></div><p>这里我们使用了GetData<byte>().ToArray()来将数据转化成需要的格式。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl"><span class="k">void</span> <span class="n">OnCompleteReadback</span><span class="p">(</span><span class="n">AsyncGPUReadbackRequest</span> <span class="n">request</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">request</span><span class="p">.</span><span class="n">hasError</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">Debug</span><span class="p">.</span><span class="n">Log</span><span class="p">(</span><span class="s">&#34;GPU readback error detected.&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">callback</span><span class="p">.</span><span class="n">Invoke</span><span class="p">(</span><span class="n">request</span><span class="p">.</span><span class="n">GetData</span><span class="p">&lt;</span><span class="kt">byte</span><span class="p">&gt;().</span><span class="n">ToArray</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span></code></pre></div><p>转化成模型可接受的数据还需要一个步骤就是把RGB[0,255] --&gt; [-1,1]进行一个域转换，然后我们使用到了Barracuda提供的Tensor数据结构。<br>
这一步就可以直接让Unity中的数据直接和我们的深度学习模型进行交互了。不过具体的数据的格式还是要看模型需要怎样的输入了，这部分比较个性化，不过基本上都是张量...</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl"> <span class="n">Tensor</span> <span class="n">TransformInput</span><span class="p">(</span><span class="kt">byte</span><span class="p">[]</span> <span class="n">pixels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">float</span><span class="p">[]</span> <span class="n">transformedPixels</span> <span class="p">=</span> <span class="k">new</span> <span class="kt">float</span><span class="p">[</span><span class="n">pixels</span><span class="p">.</span><span class="n">Length</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="p">=</span> <span class="m">0</span><span class="p">;</span> <span class="n">i</span> <span class="p">&lt;</span> <span class="n">pixels</span><span class="p">.</span><span class="n">Length</span><span class="p">;</span> <span class="n">i</span><span class="p">++)</span>
</span></span><span class="line"><span class="cl">        <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">transformedPixels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">=</span> <span class="p">(</span><span class="n">pixels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">-</span> <span class="m">127f</span><span class="p">)</span> <span class="p">/</span> <span class="m">128f</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="k">new</span> <span class="n">Tensor</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="n">IMAGE_SIZE</span><span class="p">,</span> <span class="n">IMAGE_SIZE</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="n">transformedPixels</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span></code></pre></div><h3 id="模型的推理"><a href="#模型的推理" class="anchor-link">#</a>模型的推理</h3>
<p>首先引用我们需要的模型文件，这是Barracuda提供给我们的简单应用。ModelLoader允许我们引用模型，WorkerFactory允许我们构建推理引擎。这里WorkerFactory.Type.ComputePrecompiled使用的是GPU推理，当然你需要根据平台和模型来决定最适合的引擎，有基于CPU的引擎等。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl">    <span class="kt">var</span> <span class="n">model</span> <span class="p">=</span> <span class="n">ModelLoader</span><span class="p">.</span><span class="n">Load</span><span class="p">(</span><span class="n">modelFile</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">worker</span> <span class="p">=</span> <span class="n">WorkerFactory</span><span class="p">.</span><span class="n">CreateWorker</span><span class="p">(</span><span class="n">WorkerFactory</span><span class="p">.</span><span class="n">Type</span><span class="p">.</span><span class="n">ComputePrecompiled</span><span class="p">,</span> <span class="n">model</span><span class="p">);</span>   
</span></span></code></pre></div><p>然后我们最核心的处理流程来了：</p>
<ol>
<li>调用TransformInput生成输入的tensor；</li>
<li>然后调用 worker.Execute 可以使用神经网路进行推理；</li>
<li>然后worker.PeekOutput得到largest output；</li>
<li>根据output得到最大的index，我们自定义一个LoadLabels函数得到index对应的标签，这个标签就是我们想要的结果。</li>
<li>最后记得手动释放tensor，因为Unity的GC接管不了这些资源。</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl"> <span class="n">IEnumerator</span> <span class="n">RunModelRoutine</span><span class="p">(</span><span class="kt">byte</span><span class="p">[]</span> <span class="n">pixels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">Tensor</span> <span class="n">tensor</span> <span class="p">=</span> <span class="n">TransformInput</span><span class="p">(</span><span class="n">pixels</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="kt">var</span> <span class="n">inputs</span> <span class="p">=</span> <span class="k">new</span> <span class="n">Dictionary</span><span class="p">&lt;</span><span class="kt">string</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">&gt;</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="p">{</span> <span class="n">INPUT_NAME</span><span class="p">,</span> <span class="n">tensor</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">};</span>
</span></span><span class="line"><span class="cl">        <span class="n">worker</span><span class="p">.</span><span class="n">Execute</span><span class="p">(</span><span class="n">inputs</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">Tensor</span> <span class="n">outputTensor</span> <span class="p">=</span> <span class="n">worker</span><span class="p">.</span><span class="n">PeekOutput</span><span class="p">(</span><span class="n">OUTPUT_NAME</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="c1">//get largest output</span>
</span></span><span class="line"><span class="cl">        <span class="n">List</span><span class="p">&lt;</span><span class="kt">float</span><span class="p">&gt;</span> <span class="n">temp</span> <span class="p">=</span> <span class="n">outputTensor</span><span class="p">.</span><span class="n">ToReadOnlyArray</span><span class="p">().</span><span class="n">ToList</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">        <span class="kt">float</span> <span class="n">max</span> <span class="p">=</span> <span class="n">temp</span><span class="p">.</span><span class="n">Max</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">        <span class="kt">int</span> <span class="n">index</span> <span class="p">=</span> <span class="n">temp</span><span class="p">.</span><span class="n">IndexOf</span><span class="p">(</span><span class="n">max</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1">//显示结果输出到UI Text</span>
</span></span><span class="line"><span class="cl">        <span class="n">uiText</span><span class="p">.</span><span class="n">text</span> <span class="p">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">        <span class="c1">//dispose tensors</span>
</span></span><span class="line"><span class="cl">        <span class="n">tensor</span><span class="p">.</span><span class="n">Dispose</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">        <span class="n">outputTensor</span><span class="p">.</span><span class="n">Dispose</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">        <span class="k">yield</span> <span class="k">return</span> <span class="kc">null</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span></code></pre></div><h3 id="根据index得到标签结果"><a href="#根据index得到标签结果" class="anchor-link">#</a>根据Index得到标签结果</h3>
<p>在一开始我们可以设置一个string[] 存放结果标签，使用index来查表获得结果即可。流程从上一部分的显示结果输出到UI Text开始。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl">    <span class="k">void</span> <span class="n">LoadLabels</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="c1">// 得到index对应的标签</span>
</span></span><span class="line"><span class="cl">        <span class="kt">var</span> <span class="n">stringArray</span> <span class="p">=</span> <span class="n">labelAsset</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">Split</span><span class="p">(</span><span class="sc">&#39;&#34;&#39;</span><span class="p">).</span><span class="n">Where</span><span class="p">((</span><span class="n">item</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="p">=&gt;</span> <span class="n">index</span> <span class="p">%</span> <span class="m">2</span> <span class="p">!=</span> <span class="m">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">labels</span> <span class="p">=</span> <span class="n">stringArray</span><span class="p">.</span><span class="n">Where</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="p">=&gt;</span> <span class="n">i</span> <span class="p">%</span> <span class="m">2</span> <span class="p">!=</span> <span class="m">0</span><span class="p">).</span><span class="n">ToArray</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span></code></pre></div><p>为了节约资源，我使用Button调用函数，这样我们不必每一帧都执行模型推理，其实实时识别是可以做到的，但是手机的帧率会急剧下降，所以还是建议使用button来决定什么时候进行推理识别。</p>
<h2 id="结果--outro"><a href="#结果--outro" class="anchor-link">#</a>结果 &amp; Outro</h2>
<p>经过测试，我的手机毫无压力的得到了不错的识别结果。
注：在代码里我强制使用了30帧来节约资源。识别的结果如下（重做了新的UI界面）:<br>
<img alt="识别结果截图" src="/images/2022/image_recognition_result_new.png"></p>
<h3 id="未来的方向"><a href="#未来的方向" class="anchor-link">#</a>未来的方向</h3>
<p>其实这只是一个很普通简单的例子，真正有价值的是，在游戏引擎里面使用恰当的机器学习模型能让游戏变得更加有趣。能在Unity3D里面实现物体识别，短期就能实时其中里面做到物体追踪，图像分割。更加长远的目标是用让深度学习的模型来构建游戏内容，比如一个更智能的卡牌游戏AI，比如一个完全由机器学习模型生成的NPC，或者NPC讲故事时，故事的文本完全由模型生成。这样一来，游戏的随机性会得到质的飞跃。</p>
<p>我近期的目标是把节奏检测的神经网络集成到我的独立demo里面，我想让玩家能够在一个完全支持自定义的泛音游里面找到自己的乐趣。不过想要把conda环境和神经网路的各种依赖关系无缝集成到Unity\Unreal或者其他引擎里面去，还是需要很长一段路要走。</p>
<p>关于这个简单的图像识别Demo，它所有的代码都是开源的，请在下面的地址下载工程文件以及打包好的apk文件，
(我只在自己的安卓10的Oneplus 6上做过测试，文件不支持IOS)：</p>
<ul>
<li><a href="https://github.com/yangmingxian/Unity-Image-Classification" target="_blank" rel="noopener"><strong>工程文件地址</strong></a></li>
</ul>
<h2 id="others"><a href="#others" class="anchor-link">#</a>Others</h2>
<ul>
<li><a href="https://yangmingxian.com/" target="_blank" rel="noopener"><strong>作者博客：YMX's Site</strong></a></li>
<li><a href="https://space.bilibili.com/22212765" target="_blank" rel="noopener"><strong>作者B站视频：CyberStreamer</strong></a></li>
</ul>

            </div>

            


        </article>

        

        


        


        


        


        


        
    <footer class="minimal-footer">
        
            <div class="post-tag"><a href="/tags/game-design/" rel="tag" class="post-tag-link">#game-design</a> <a href="/tags/tech/" rel="tag" class="post-tag-link">#tech</a></div>
        
        
            <div class="post-category">
                <a href="/tech/" class="post-category-link active">tech</a> | <a href="/life/" class="post-category-link">life</a>
            </div>
        
        
    </footer>



        


        


        


    </div>
</main>


            
    <div id="back-to-top" class="back-to-top">
        <a href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a>
    </div>


            
    <footer id="footer" class="footer">
        <div class="footer-inner">
            <div class="site-info">©&nbsp;2015–2024&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon footer-icon"><path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"/></svg>&nbsp;Mingxian</div>

            


            
        </div>
    </footer>


        </div>
        

        








    <script src="/libs/medium-zoom.min.js"></script>

<script>
    let imgNodes = document.querySelectorAll('div.post-body img');
    imgNodes = Array.from(imgNodes).filter(node => node.parentNode.tagName !== "A");

    mediumZoom(imgNodes, {
        background: 'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'
    })
</script>









    </body>
</html>
